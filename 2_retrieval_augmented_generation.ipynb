{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccf5dd5-145b-4a1b-841f-5fab6fec047a",
   "metadata": {},
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3be0a6-8c14-4203-88d6-b680ea30b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q chromadb\n",
    "pip install -q langchain\n",
    "pip install -q langchain-community\n",
    "pip install -q langchain-chroma\n",
    "pip install -q langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120572b-5941-4635-b2a7-a801dc3db208",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8940e634-800e-4d00-9d4d-588059a2b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb5d92-2e4d-4d69-93c1-9494acf39081",
   "metadata": {},
   "source": [
    "Initiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7877ae75-c0ae-4c58-a10e-fb61b2a6b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba709f9-4f47-4641-a91e-5a0c6329e3e5",
   "metadata": {},
   "source": [
    "Let's make up some example documents to test the model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc00523-36b4-40cf-8895-1bf34871cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=\"John has black hair. He owns 3 cats, and likes to play pickleball.\"), \n",
    "    Document(page_content=\"Jane has brown hair. She has no pets, and loves to travel and parasail.\"), \n",
    "    Document(page_content=\"Sam is bald. He has one big dog and one small dog, and enjoys writing poetry.\"),\n",
    "    Document(page_content=\"Kate has short blonde hair. She keeps a saltwater fishtank, and her hobby is knitting.\"),\n",
    "    Document(page_content=\"Jim has brown hair. He owns a dog and skateboards everywhere he goes.\"),\n",
    "    Document(page_content=\"Beth has long black hair. She owns a cat, and in her spare time she builds computers.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ae41e-f45e-44d1-8ddb-081f6886e5e0",
   "metadata": {},
   "source": [
    "We need to embed the documents into numeric vectors using another LLM. This will enable us to search based on vector similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7e03f-e52c-4cc6-b506-049b0b7ceb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206243f-1d6b-45a0-a31b-9ab41cab8a62",
   "metadata": {},
   "source": [
    "Now we can write a prompt to contextualize the documents, and leave room for the question we want to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682fe88-599f-48bf-ae75-170228cba4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context about my friends to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "\n",
    "Context: \n",
    "{context} \n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ef1d87-16cf-4f91-a0f2-2f1492f14341",
   "metadata": {},
   "source": [
    "Time to ask some questions about these documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61677121-9bec-491b-825e-3f0628ed557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"How many pets does Sam have?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
